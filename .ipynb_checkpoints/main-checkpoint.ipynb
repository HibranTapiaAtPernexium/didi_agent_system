{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de3f8ae-9c1c-49cc-a952-6ca09f763200",
   "metadata": {},
   "source": [
    "## Interfaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6f1d0-ea65-4358-b929-f4cab6291493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47778b-0cca-4a99-911d-97e1528048da",
   "metadata": {},
   "source": [
    "## Para que el agente mande la info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61feb8d-0e68-4bef-9430-d01d1a15c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile main.py\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import streamlit as st\n",
    "session = boto3.client('s3',\n",
    "    aws_access_key_id = st.secrets[\"aws\"][\"aws_access_key_id\"],\n",
    "    aws_secret_access_key = st.secrets[\"aws\"][\"aws_secret_access_key\"],\n",
    "     region_name='us-east-2'\n",
    ")\n",
    "\n",
    "# Especifica el nombre del bucket y la clave del archivo .pkl en S3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "06ab5c13-76f9-41a5-9af2-7b22dac8a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_status(agent_number, status, current_page, errors = None):\n",
    "    \n",
    "## Primero obtenemos el archivo:\n",
    "    bucket_name = 's3-pernexium-report'\n",
    "    key_folder = 'raw/didi/didi_agent/'\n",
    "    fecha = datetime.now()\n",
    "    fecha_actual = fecha.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    key_final_prospectos = f'{key_folder}{fecha_actual}/logs_agent_{agent_number}.csv'\n",
    "    \n",
    "    try:\n",
    "        response = session.get_object(Bucket=bucket_name, Key=key_final_prospectos)\n",
    "        columnas_bytes = response['Body'].read()\n",
    "        data = pd.read_csv(BytesIO(columnas_bytes))\n",
    "    except:\n",
    "        data = None\n",
    "    \n",
    "    \n",
    "    # Si ya hay uno, se hace un append\n",
    "    fecha_hora_actual = fecha.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    payload = [agent_number, fecha_hora_actual, status, current_page, errors]\n",
    "    \n",
    "    data_ = pd.DataFrame(payload).T\n",
    "    data_.columns = [\"agent_number\", \"last_update\", \"last_status\", \"current_page\", \"errors\"]\n",
    "    \n",
    "    if data is not None:\n",
    "        data = pd.concat([data, data_])\n",
    "    else:\n",
    "        data = data_\n",
    "        \n",
    "    # Convertir DataFrame a CSV en memoria\n",
    "    csv_buffer = data.to_csv(index=False)\n",
    "    \n",
    "    # Subir el archivo CSV a S3 directamente desde la memoria\n",
    "    response = session.put_object(Bucket=bucket_name, Key=key_final_prospectos, Body=csv_buffer)\n",
    "    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "        print(\"Enviado correctamente\")\n",
    "    else:\n",
    "        print(\"Error en la carga\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb246cc8-d246-42ef-96d0-250814ef6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sin pandas\n",
    "import csv\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "def send_status(agent_number, status, current_page, errors=None):\n",
    "    # Primero obtenemos el archivo:\n",
    "    bucket_name = 's3-pernexium-report'\n",
    "    key_folder = 'raw/didi/didi_agent/'\n",
    "    fecha = datetime.now()\n",
    "    fecha_actual = fecha.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    key_final_prospectos = f'{key_folder}{fecha_actual}/logs_agent_{agent_number}.csv'\n",
    "    \n",
    "    try:\n",
    "        response = session.get_object(Bucket=bucket_name, Key=key_final_prospectos)\n",
    "        columnas_bytes = response['Body'].read()\n",
    "        data = columnas_bytes.decode('utf-8')\n",
    "        rows = list(csv.reader(StringIO(data)))\n",
    "    except:\n",
    "        rows = []\n",
    "\n",
    "    # Si ya hay uno, se hace un append\n",
    "    fecha_hora_actual = fecha.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    payload = [agent_number, fecha_hora_actual, status, current_page, errors]\n",
    "    \n",
    "    # Crear CSV en memoria\n",
    "    output = StringIO()\n",
    "    writer = csv.writer(output)\n",
    "    \n",
    "    if rows:\n",
    "        writer.writerows(rows)  # Escribe las filas existentes\n",
    "    else:\n",
    "        # Definir las columnas si no hay datos\n",
    "        writer.writerow([\"agent_number\", \"last_update\", \"last_status\", \"current_page\", \"errors\"])\n",
    "    \n",
    "    writer.writerow(payload)  # Añadir la nueva fila\n",
    "    \n",
    "    csv_buffer = output.getvalue()\n",
    "    \n",
    "    # Subir el archivo CSV a S3 directamente desde la memoria\n",
    "    response = session.put_object(Bucket=bucket_name, Key=key_final_prospectos, Body=csv_buffer)\n",
    "    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "        print(\"Enviado correctamente\")\n",
    "    else:\n",
    "        print(\"Error en la carga\")\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069f9945-1664-47a8-b5f1-cb1b02bed247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enviado correctamente\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['agent_number', 'last_update', 'last_status', 'current_page', 'errors'],\n",
       " ['3', '2024-08-26 17:08:27', 'Running', '50/68', ''],\n",
       " ['3', '2024-08-26 17:08:52', 'Finished', '50/68', '']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_status(agent_number = 3, status = 'Finished', current_page = '51/68', errors = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "09941848-7950-412b-bf88-fde66f27298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    int(1)\n",
    "except Exception as e:\n",
    "    send_status(agent_number = 2, status = 'Todo bien', current_page = '20/20', errors = \"Llamen a Dios\\n\"+str(e))\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e570fd5-3c64-457d-bbb5-5a7cbd825dfa",
   "metadata": {},
   "source": [
    "## Para el servidor que la recibe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ba08b2df-82f1-4367-b878-ae46670c6f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import streamlit as st\n",
    "import pytz\n",
    "\n",
    "\n",
    "session = boto3.client('s3',\n",
    "    aws_access_key_id = st.secrets[\"aws\"][\"aws_access_key_id\"],\n",
    "    aws_secret_access_key = st.secrets[\"aws\"][\"aws_secret_access_key\"],\n",
    "     region_name='us-east-2'\n",
    ")\n",
    "\n",
    "# Especifica el nombre del bucket y la clave del archivo .pkl en S3\n",
    "def get_data(fecha_buscar):\n",
    "    data_general = pd.DataFrame()\n",
    "    bucket_name = 's3-pernexium-report'\n",
    "    key_folder = f'raw/didi/didi_agent/{fecha_buscar}/'\n",
    "    \n",
    "    response = session.list_objects_v2(Bucket=bucket_name, Prefix=key_folder)\n",
    "        \n",
    "    if 'Contents' in response:\n",
    "        # Itera sobre cada archivo en el folder\n",
    "        for obj in response['Contents']:\n",
    "            key = obj['Key']\n",
    "            print(f\"Leyendo el archivo: {key}\")\n",
    "    \n",
    "            # Obtén el objeto desde S3\n",
    "            file_response = session.get_object(Bucket=bucket_name, Key=key)\n",
    "            \n",
    "            # Lee el contenido del archivo en bytes\n",
    "            columnas_bytes = file_response['Body'].read()\n",
    "    \n",
    "            # Usa BytesIO para leer el contenido como un DataFrame de pandas\n",
    "            df = pd.read_csv(BytesIO(columnas_bytes))\n",
    "    \n",
    "            # Realiza cualquier operación que necesites con el DataFrame\n",
    "            data_general = pd.concat([data_general, df])\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos en el folder {key_folder} del bucket {bucket_name}.\")\n",
    "        return None\n",
    "\n",
    "    data_general_raw = data_general.copy()\n",
    "    data_general_raw[\"page\"] = data_general_raw.current_page.apply(lambda x: int(x.split(\"/\")[0]))\n",
    "    data_general = data_general.sort_values(by = \"last_update\", ascending=False).drop_duplicates(subset = [\"agent_number\"], keep=\"first\")\n",
    "    data_general['progress'] = data_general.current_page.apply(lambda x: int(x.split(\"/\")[0]) / int(x.split(\"/\")[1]))\n",
    "\n",
    "    data_general = data_general[['agent_number', 'last_update', 'last_status', 'current_page', 'progress', 'errors']]\n",
    "    data_general = data_general.sort_values(by = 'agent_number')\n",
    "    return data_general, data_general_raw\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Pernexium Agentes Automáticos\",\n",
    "    page_icon=\"./img/logo_pernexium.png\"  # Puedes usar una ruta local o una URL\n",
    ")\n",
    "\n",
    "st.header(\"Interfaz de control para agentes automáticos\")\n",
    "\n",
    "mexico_city_tz = pytz.timezone('America/Mexico_City')\n",
    "\n",
    "# Obtén la fecha y hora actual en la zona horaria de Ciudad de México\n",
    "hoy = datetime.now(mexico_city_tz).date()\n",
    "#st.write(hoy)\n",
    "\n",
    "# Selector de fechas con la fecha de hoy como valor predeterminado\n",
    "col1, col2 = st.columns([9, 1])\n",
    "with col1:\n",
    "    fecha_seleccionada = st.date_input(\"Seleccione una fecha:\", hoy)\n",
    "with col2:\n",
    "    #st.write(\"#\")\n",
    "    st.button('🔄')\n",
    "\n",
    "data, data_raw = get_data(fecha_seleccionada)\n",
    "\n",
    "data_raw.last_update = pd.to_datetime(data_raw.last_update)\n",
    "\n",
    "total_gestionado = 20 * (data_raw.groupby(\"agent_number\").page.max() - data_raw.groupby(\"agent_number\").page.min()).sum()\n",
    "\n",
    "agentes_corriendo = data_raw.agent_number.nunique()\n",
    "\n",
    "gestiones_medias = int(total_gestionado/agentes_corriendo)\n",
    "\n",
    "tiempo_medio_por_gestion = sum([data_raw.query(f\"agent_number == {an}\").last_update.diff().mean().total_seconds() / 20 for an in range(1, agentes_corriendo+1)])/ agentes_corriendo\n",
    "\n",
    "gestiones_en_ocho_horas = (9*60*60) / tiempo_medio_por_gestion\n",
    "\n",
    "    \n",
    "if data is None:\n",
    "    st.warning(\"No hay información para la fecha seleccionada\")\n",
    "else:\n",
    "    st.data_editor(data, disabled = True, \n",
    "                   column_config={\n",
    "                    \"progress\": st.column_config.ProgressColumn(\n",
    "                        \"Progress\",\n",
    "                        help=\"Progreso\",\n",
    "                        #format=\"%f\",\n",
    "                        min_value=0,\n",
    "                        max_value=1,\n",
    "                    ),\n",
    "                },\n",
    "                hide_index=True,)\n",
    "\n",
    "col1, col2  = st.columns(2)\n",
    "col1.metric(label = \"Total de Cuentas gestionadas en el día\", value = str(total_gestionado))\n",
    "\n",
    "col2.metric(label = \"Promedio de cuentas por agente en jornada\", value = f\"{gestiones_en_ocho_horas:.0f}\", delta = f'{gestiones_en_ocho_horas - 350:.0f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76807296-5d3f-42fa-86cc-c0e1d0db52f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['agent_number', 'last_update', 'last_status', 'current_page', 'errors',\n",
       "       'progress'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_general.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61546fb1-cdc4-4a05-8663-454aa1069c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_general = data_general.sort_values(by = \"last_update\", ascending=False).drop_duplicates(subset = [\"agent_number\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216fbee1-cce3-4227-b88f-a309e2c7c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_1.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_10.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_2.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_3.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_4.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_5.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_6.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_7.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_8.csv\n",
      "Leyendo el archivo: raw/didi/didi_agent/2024-08-30/logs_agent_9.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import streamlit as st\n",
    "import pytz\n",
    "\n",
    "session = boto3.client('s3',\n",
    "    aws_access_key_id = st.secrets[\"aws\"][\"aws_access_key_id\"],\n",
    "    aws_secret_access_key = st.secrets[\"aws\"][\"aws_secret_access_key\"],\n",
    "     region_name='us-east-2'\n",
    ")\n",
    "\n",
    "# Especifica el nombre del bucket y la clave del archivo .pkl en S3\n",
    "def get_data(fecha_buscar):\n",
    "    data_general = pd.DataFrame()\n",
    "    bucket_name = 's3-pernexium-report'\n",
    "    key_folder = f'raw/didi/didi_agent/{fecha_buscar}/'\n",
    "    \n",
    "    response = session.list_objects_v2(Bucket=bucket_name, Prefix=key_folder)\n",
    "        \n",
    "    if 'Contents' in response:\n",
    "        # Itera sobre cada archivo en el folder\n",
    "        for obj in response['Contents']:\n",
    "            key = obj['Key']\n",
    "            print(f\"Leyendo el archivo: {key}\")\n",
    "    \n",
    "            # Obtén el objeto desde S3\n",
    "            file_response = session.get_object(Bucket=bucket_name, Key=key)\n",
    "            \n",
    "            # Lee el contenido del archivo en bytes\n",
    "            columnas_bytes = file_response['Body'].read()\n",
    "    \n",
    "            # Usa BytesIO para leer el contenido como un DataFrame de pandas\n",
    "            df = pd.read_csv(BytesIO(columnas_bytes))\n",
    "    \n",
    "            # Realiza cualquier operación que necesites con el DataFrame\n",
    "            data_general = pd.concat([data_general, df])\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos en el folder {key_folder} del bucket {bucket_name}.\")\n",
    "        return None\n",
    "\n",
    "    data_general_raw = data_general.copy()\n",
    "    data_raw[\"page\"] = data_raw.current_page.apply(lambda x: int(x.split(\"/\")[0]))\n",
    "    data_general = data_general.sort_values(by = \"last_update\", ascending=False).drop_duplicates(subset = [\"agent_number\"], keep=\"first\")\n",
    "    data_general['progress'] = data_general.current_page.apply(lambda x: int(x.split(\"/\")[0]) / int(x.split(\"/\")[1]))\n",
    "\n",
    "    data_general = data_general[['agent_number', 'last_update', 'last_status', 'current_page', 'progress', 'errors']]\n",
    "    data_general = data_general.sort_values(by = 'agent_number')\n",
    "    return data_general, data_general_raw\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Pernexium Agentes Automáticos\",\n",
    "    page_icon=\"./img/logo_pernexium.png\"  # Puedes usar una ruta local o una URL\n",
    ")\n",
    "\n",
    "st.header(\"Interfaz de control para agentes automáticos\")\n",
    "\n",
    "mexico_city_tz = pytz.timezone('America/Mexico_City')\n",
    "\n",
    "# Obtén la fecha y hora actual en la zona horaria de Ciudad de México\n",
    "hoy = datetime.now(mexico_city_tz).date()\n",
    "\n",
    "data, data_raw = get_data(hoy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "780b42ff-5f5e-4acc-a038-1680c3533509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[\"page\"] = data_raw.current_page.apply(lambda x: int(x.split(\"/\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33c4bb2b-5ff9-4702-911e-2e1c820ef442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_raw.groupby(\"agent_number\").page.max() - data_raw.groupby(\"agent_number\").page.min()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "192bc214-8170-44ee-b18d-91cfd8498775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.last_update = pd.to_datetime(data_raw.last_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b7df5337-ee4a-4670-83fa-395a477a87fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.17484835500001"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentes_corriendo = 10\n",
    "sum([data_raw.query(f\"agent_number == {an}\").last_update.diff().mean().total_seconds() / 20 for an in range(1,agentes_corriendo+1)])/ agentes_corriendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2ce8d374-82c8-4453-8408-5832a5a30c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_update\n",
       "2024-08-30    2265\n",
       "Name: page, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupar por día\n",
    "data_raw.groupby(data_raw['last_update'].dt.date).page.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
